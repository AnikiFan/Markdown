# Artificial Intelligence

## Introduction

- 授课内容：3,5,7,8,9,12,13,19章

## Searching

### Formulation

- World State: the state that consists of every details, which is usually much redundant and not quite helpful to solve the searching problem
- Search State: the state that only contains the information necessary for the agent to solve the planning problem. It is a part of the world state
  - searching for an optimal path: the current location is the only element in the search state.
  - traverse the whole space: not only the current location, but also a boolean matrix, which record whether certain location have been visited, are need to form a complete state space. In other words, in this case, we have to keep track of the history.
- goal test: a test *only based on state* to tell whether or not the agent have achieved the goal and can stop acting.

> NOTE
> since the goal test can *only base on the state*, it is helpful to consider what elements are necessary part of a goal test or goal itself, when deciding what are to be included in the state space. For instance, when our goal is traversing all the city, when we test whether we have achieved the goal, we actually have to look back to check out whether we have made to every cities. In other word, we have to have a boolean matrix in the state to record the history.

### State Graph VS. Searching Tree

In state graph, each node represent a state, and the arc connecting two nodes represent the action that makes the action move from one state to another.

While in searching tree, a node *represent a path(solution)* from the starting state to the state of that node.

Therefore, even if the state graph for a particular planning problem is finite, it can have an infinite searching tree due to infinite loop.

### Searching Algorithm

#### Genearl Searching Algorithm

We can directly get the path to the goal state if we have access to the whole searching tree. However, in most cases, it is too big to be stored in the computer. Therefore, the basic idea of the general searching algorithm goes like this:

1. pick a node from the frontier
2. check whether that node is the goal state
   - if it is, then the work is done
   - otherwise, expand that node and add its children to the frontier
3. loop

> NOTE
> the node in the frontier also represent a path instead of only a node, so that there may be many nodes with the same state in the frontier, but they can represent different path to that very state.

Most of the searching algorithm share the same structure with the general one, the only difference is the strategy they used for choosing which node from the frontier.

> NOTE
> when simulating the way algorithm find out the solution, we have to strictly follow the solution. For instance, even if a node with the goal state has been added to the frontier, not before we pick it out by some kind of strategy can we say that we find the solution

#### $A^*$ Tree Search and Admissiblity

We can proof that if a suboptimal goal node has entered the frontier, all the node on the real optimal solution path will leave the frontier, including the optimal goal node itself, will leave the frontier sooner than it.

Given a problem, if we remove some restriction and get a new problem where for each node, the agent has more or the same actions to take, then we call the new one the relaxed problem of the former one. It is easy to see that the optimal solution for the relaxed problem always cost less than the original's. Therefore, one can always get a admissible heuristic function for a particular problem by relaxing it and finding the optimal solution for it as the heuristic function's value. On the other hand, to show that a given function is admissible, it is also very useful to fit it into some relaxed form of the given problem, and we will then finish the proof at once by the property the relaxed problem own.

#### $A^*$ Graph Search and Consistency

The only difference between tree search and graph search is that in the latter case, the node that has expanded won't be expanded twice. So here comes the problem, even if the heuristic function is admissible, the $A^*$ graph search don't guarentee to give the optimal solution. For instance, if a series of node are 'over optimistic' so that they lead the agent to follow the wrong path and let it unable to return to the optimal path, since the node on it has already been expanded. To solve this problem, we need the heuristic function to be consistent. In other word, no heuristic function value will be 'over optimistic'. More formally, the consitent heuristic function has to obey the triangle inequality. Surprisingly, the heuristic function derived from the optimal solution of the relaxed problem obey the triangle inequality naturally, therefore, not only is it admissible, but it is also consistent. Whenever the heuristic function is consistent, the first time each node enter the frontier, it must be approached along the optimal path with minimum $g$ value.

### Simulating Annealing Algorithm

In Simulating Annealing Algorithm, there is a parameter called Temperature. Same as other searching algorithm, if there are better adjacent state, then the agent turn into that state. However, when there are no better adjacent state, there is possibility for the agent to leave the current state. The possibility is proportional to $e^{\frac{\Delta E}{T}}$, where $\Delta E$ is the difference between the 'score' of the two states.

### Adversial Searching

The original minimax algorithm for adversial searhing is similar to the *exhausted* DFS. In other word, it has to traverse all the possible state to return the final answer. It is actually a postorder search. Therefore, the time complexity is $O(b^m)$, and the space complexity is $O(bm)$

#### $\alpha-\beta$Pruning

The essence of pruning is to use the information already got to decide whether continuing exploring some subtrees can make any change to the answer we want.

When thinking of $\alpha-\beta$ pruning, we must realized that the $\alpha$ or $\beta$ value we have already got represent some existing path, therefore, when we can show that the path passing by the current path will not be better than that existing path, we can pruning this node and the following subtree.

#### Expectiminimax

When randomness appear in the game, we have to take it into consideration. One way to do it is to use the expectiminimax instead of ordinary minimax. In other word, we have to consider each possible conditions and weigh they with their possiblity.

#### Multi-agent Game

Dynamic cooperations may arise in such cases, even if we don't intentionally let the agents do so. For example, when there are several ghosts in the pac-man game, since they goals are both eating the pac-man, and they act according to other's action to maximaize their scores, chances are that they may surround the pac-man so that the pac-man is doomed.

## Logic

### Propositional Logic

The synatx are what sentences are allowed, while the semantics is what we follows to tell whether a given sentence is true or not in a given world, in other word, it is the truth itself.

Entailment is the conception of the logic itself and is defined only by the concept of synatx, semantics and world. More exactly
\[\alpha\models\beta iff M(\alpha)\subseteq M(\beta)\]

While implies$\Rightarrow$ is specific to certain kind of logic, such as porpositional logic.
