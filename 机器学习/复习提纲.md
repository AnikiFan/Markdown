# 复习提纲

## 开学篇

## 线性回归

1. 3种梯度下降的方法
2. 多变量线性回归和单变量回归相比可能会出现那些问题
3. 学习率优化器
4. 正则化方法
5. 梯度下降和最下二乘法的对比
6. 回归评价标准
7. Lasso回归是否可以通过求导得到闭式解？
8. 回归算法

## 线性分类

1. 线性分类算法
2. 对数几率
3. 交叉熵损失函数与极大似然法之间的关联
4. 二元线性判别分析结论
5. 类别不平衡问题
6. 评价标准
7. 为什么逻辑蒂斯回归算法的梯度公式和线性回归的梯度公式和相似。它们之间又有什么不同？

## 决策树

1. 决策树的表达能力
2. 决策树学习通用算法（停止规则）
3. ID3
4. C4.5
5. CART
6. 连续值问题
7. 缺失值问题
8. 模型选择
9. 树剪枝
10. 多变量决策树
11. 决策树算法是否有必要作特征缩放？

## 神经网络

1. 神经网络和人脑的联系
2. 感知机训练法则
3. 感知机局限
4. 反向传播法则
5. 反向传播的优缺点
6. 多层神经网络的表征能力
7. 激活函数在神经网络中起到了什么作用？
8. 在bp算法训练神经网络时，激活函数在哪些计算步骤中会被涉及？

## 深度学习

1. 神经网络发展的三阶段
2. 深度学习和传统机器学习之间的对比
3. 为什么深度学习强调“深”
4. CNN
5. 深度学习中的困难及其解决方法
6. Dropout
7. 深度神经网络相比传统神经网络训练会有哪些问题，有哪些解决的思路？

## SVM

1. 线性SVM与逻辑蒂斯回归之间的区别
2. 用于SVM的损失函数
3. SVM最重要的两个特点
4. 核技巧

## 贝叶斯学习

1. 判别模型和生成模型之间的对比
2. 贝叶斯公式中各项的含义
3. MAP与MLP之间的对比
4. MAP和最可能分类之间的区别
