# 复习提纲

## 开学篇

1. 人工智能的三大方法
2. 机器学习与传统编程的不同
3. 机器学习的适用领域
4. 机器学习的定义
5. 机器学习的条件
6. 机器学习的四大任务
7. 三大学习任务类型
8. 机器学习依赖的基本假设
9. 常见损失函数
10. 常见超参数
11. 超参数优化方法
12. Loss/Cost/Objective function
13. 交叉验证
14. Variance & Bias
15. 对于欠拟合和过拟合的处理方法
16. 回归任务评价标准
17. 分类任务评价标准
18. 机器学习和假设空间
19. 函数表征
20. 搜索算法
21. 在什么情况下会同时出现高偏差和高方差

## 线性回归

1. 3种梯度下降的方法
2. 多变量线性回归和单变量回归相比可能会出现那些问题
3. 学习率优化器
4. 正则化方法
5. 梯度下降和最下二乘法的对比
6. 回归评价标准
7. Lasso回归是否可以通过求导得到闭式解？
8. 回归算法

## 线性分类

1. 线性分类算法
2. 对数几率
3. 交叉熵损失函数与极大似然法之间的关联
4. 二元线性判别分析结论
5. 类别不平衡问题
6. 评价标准
7. 为什么逻辑蒂斯回归算法的梯度公式和线性回归的梯度公式和相似。它们之间又有什么不同？

## 决策树

1. 决策树的表达能力
2. 决策树学习通用算法（停止规则）
3. ID3
4. C4.5
5. CART
6. 连续值问题
7. 缺失值问题
8. 模型选择
9. 树剪枝
10. 多变量决策树
11. 决策树算法是否有必要作特征缩放？

## 神经网络

1. 神经网络和人脑的联系
2. 感知机训练法则
3. 感知机局限
4. 反向传播法则
5. 反向传播的优缺点
6. 多层神经网络的表征能力
7. 激活函数在神经网络中起到了什么作用？
8. 在bp算法训练神经网络时，激活函数在哪些计算步骤中会被涉及？

## 深度学习

1. 神经网络发展的三阶段
2. 深度学习和传统机器学习之间的对比
3. 为什么深度学习强调“深”
4. CNN
5. 卷积操作特点
6. 降采样操作特点
7. 深度学习中的困难及其解决方法
8. 激活函数选择准则
9. RELU特点
10. Dropout
11. 深度神经网络相比传统神经网络训练会有哪些问题，有哪些解决的思路？

## SVM

1. SVM的性质
2. 松弛项含义
3. 正则化参数含义
4. 线性SVM与逻辑蒂斯回归之间的区别
5. 用于SVM的损失函数
6. SVM最重要的两个特点
7. 核技巧

## 贝叶斯学习

1. 判别模型和生成模型之间的对比
2. 贝叶斯公式中各项的含义
3. Brute-Force MAP
4. MAP与MLP之间的对比
5. 贝叶斯最优分类器
6. 朴素贝叶斯分类器
7. 贝叶斯信念网
8. MAP和最可能分类之间的区别
9. EM算法
10. 用EM算法训练GMM

## 集成学习

1. 集成学习对于基模型的要求
2. 集成的多样性体现及其测量
3. 模型结合的基本方法
4. Stacking
5. Bagging
6. 自主采样
7. 随机森林及其优点
8. Boosting
9. AdaBoost
10. GDBT
11. GDBT与CART之间的对比
12. XGBoost
13. LightGBM

## 聚类

1. 聚类分析定义
2. 聚类应用
3. 主要聚类方法
4. K-means
5. K-means初始点问题解决方法
6. 二分K-means
7. 空类簇解决方法
8. K-means预/后处理
9. K-means局限及其解决方法
10. 层次聚类优点
11. 列簇间相似度度量方法及其优缺点
12. 基于密度的聚类的优点
13. DBSCAN算法
14. 三种聚类评价指标

## 降维

1. 降维方法
2. PCA三种实现
3. PCA应用
4. PCA缺点
5. t-SNE算法及其优点
6. 自编码器
7. 自编码器应用
8. 非负矩阵分解
9. ICA假设
10. ICA算法
11. ICA应用
12. 三种特征选择的方法及其特点
