# Artificial Intelligence

## Introduction

- 授课内容：3,5,7,8,9,12,13,19章

## Searching

### Formulation

- World State: the state that consists of every details, which is usually much redundant and not quite helpful to solve the searching problem
- Search State: the state that only contains the information necessary for the agent to solve the planning problem. It is a part of the world state
  - searching for an optimal path: the current location is the only element in the search state.
  - traverse the whole space: not only the current location, but also a boolean matrix, which record whether certain location have been visited, are need to form a complete state space. In other words, in this case, we have to keep track of the history.
- goal test: a test *only based on state* to tell whether or not the agent have achieved the goal and can stop acting.

> NOTE
> since the goal test can *only base on the state*, it is helpful to consider what elements are necessary part of a goal test or goal itself, when deciding what are to be included in the state space. For instance, when our goal is traversing all the city, when we test whether we have achieved the goal, we actually have to look back to check out whether we have made to every cities. In other word, we have to have a boolean matrix in the state to record the history.

### State Graph VS. Searching Tree

In state graph, each node represent a state, and the arc connecting two nodes represent the action that makes the action move from one state to another.

While in searching tree, a node *represent a path(solution)* from the starting state to the state of that node.

Therefore, even if the state graph for a particular planning problem is finite, it can have an infinite searching tree due to infinite loop.

### Searching Algorithm

#### Genearl Searching Algorithm

We can directly get the path to the goal state if we have access to the whole searching tree. However, in most cases, it is too big to be stored in the computer. Therefore, the basic idea of the general searching algorithm goes like this:

1. pick a node from the frontier
2. check whether that node is the goal state
   - if it is, then the work is done
   - otherwise, expand that node and add its children to the frontier
3. loop

> NOTE
> the node in the frontier also represent a path instead of only a node, so that there may be many nodes with the same state in the frontier, but they can represent different path to that very state.

Most of the searching algorithm share the same structure with the general one, the only difference is the strategy they used for choosing which node from the frontier.

> NOTE
> when simulating the way algorithm find out the solution, we have to strictly follow the solution. For instance, even if a node with the goal state has been added to the frontier, not before we pick it out by some kind of strategy can we say that we find the solution

#### $A^*$ Tree Search

We can proof that if a suboptimal goal node has entered the frontier, all the node on the real optimal solution path will leave the frontier, including the optimal goal node itself, will leave the frontier sooner than it.
