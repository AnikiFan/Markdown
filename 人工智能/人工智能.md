# Artificial Intelligence

## Introduction

- 授课内容：3,5,7,8,9,12,13,19章

### AI历史发展

- 40年代发迹
- 70年代符号学派兴起
- 90年代统计方法兴起
- 三大学派：
  - 符号学派（逻辑学派）：数理逻辑，知识表示
  - 连接学派（仿生学派）：仿生，神经网络
  - 行为学派（控制学派）：控制论，自主机器人

### 智能体

- 定义：通过传感器感知所处环境，并通过执行器对该环境产生作用的事物
- 智能体=体系结构+程序
  - 体系结构：某个具备物理传感器和执行器的计算装置
  - 智能体程序：将感知序列映射到行动的函数
- 理性的智能体：最大化性能度量的期望，依赖于：
  - 性能度量的定义
  - 先验知识
  - 可采取行动
  - 目前的感知序列
- 智能体类型：
  - 简单反射智能体：只基于当前感知选择行动，***不关注感知历史***
  - 基于模型的***反射***智能体：根据感知历史，维护内部的状态，需要知道世界是如何独立于智能体发展的，以及智能体自身的行动会如何影响世界，从而能够不断更新当前的状态（需要这两点，才能依据当前状态以及执行的动作推断出孩子结点的状态）
  - 基于目标的智能体：需要目标信息，需要考虑对未来的影响，原则上要求会推理
  - 基于效用的智能体：以效用作为选择行动的依据，最大化效用的期望
  - 学习智能体：所有智能体都可以学习，由四个组件组成
    - 性能元件：感知信息并作决策
    - 学习元件：改进性能元件
    - 评判元件：观察世界并把消息传递给学习元件
    - 问题产生器：建议少量探索行为
- 任务环境描述PEAS：
  - 性能度量（Performance）
  - 环境（Environment）
    - 可完全观察：智能体能在每一时刻获取环境的完整状态
    - 确定性/随机的：是否有突发情况
    - 静态的/半静态的：环境是否随时间变化
    - 离散/连续
    - 单个Agent/多Agent
  - 执行器（Actuators）
  - 传感器（Sensors）

## Searching

### Formulation

- 五部分组成：
  - 初始状态
  - 给定状态下的可能行动
  - 生成孩子结点的转移模型函数
  - 目标测试函数
  - 路径耗散函数

- World State: the state that consists of every details, which is usually much redundant and not quite helpful to solve the searching problem
- Search State: the state that only contains the information necessary for the agent to solve the planning problem. It is a part of the world state
  - searching for an optimal path: the current location is the only element in the search state.
  - traverse the whole space: not only the current location, but also a boolean matrix, which record whether certain location have been visited, are need to form a complete state space. In other words, in this case, we have to keep track of the history.
- goal test: a test *only based on state* to tell whether or not the agent have achieved the goal and can stop acting.

> NOTE
> since the goal test can *only base on the state*, it is helpful to consider what elements are necessary part of a goal test or goal itself, when deciding what are to be included in the state space. For instance, when our goal is traversing all the city, when we test whether we have achieved the goal, we actually have to look back to check out whether we have made to every cities. In other word, we have to have a boolean matrix in the state to record the history.

### State Graph VS. Searching Tree

In state graph, each node represent a state, and the arc connecting two nodes represent the action that makes the action move from one state to another.

While in searching tree, a node *represent a path(solution)* from the starting state to the state of that node.

Therefore, even if the state graph for a particular planning problem is finite, it can have an infinite searching tree due to infinite loop.

### Searching Algorithm

#### Genearl Searching Algorithm

We can directly get the path to the goal state if we have access to the whole searching tree. However, in most cases, it is too big to be stored in the computer. Therefore, the basic idea of the general searching algorithm goes like this:

1. pick a node from the frontier
2. check whether that node is the goal state
   - if it is, then the work is done
   - otherwise, expand that node and add its children to the frontier
3. loop

> NOTE
> the node in the frontier also represent a path instead of only a node, so that there may be many nodes with the same state in the frontier, but they can represent different path to that very state.

Most of the searching algorithm share the same structure with the general one, the only difference is the strategy they used for choosing which node from the frontier.

> NOTE
> when simulating the way algorithm find out the solution, we have to strictly follow the solution. For instance, even if a node with the goal state has been added to the frontier, not before we pick it out by some kind of strategy can we say that we find the solution

#### $A^*$ Tree Search and Admissiblity

We can proof that if a suboptimal goal node has entered the frontier, all the node on the real optimal solution path will leave the frontier, including the optimal goal node itself, will leave the frontier sooner than it.

Given a problem, if we remove some restriction and get a new problem where for each node, the agent has more or the same actions to take, then we call the new one the relaxed problem of the former one. It is easy to see that the optimal solution for the relaxed problem always cost less than the original's. Therefore, one can always get a admissible heuristic function for a particular problem by relaxing it and finding the optimal solution for it as the heuristic function's value. On the other hand, to show that a given function is admissible, it is also very useful to fit it into some relaxed form of the given problem, and we will then finish the proof at once by the property the relaxed problem own.

#### $A^*$ Graph Search and Consistency

The only difference between tree search and graph search is that in the latter case, the node that has expanded won't be expanded twice. So here comes the problem, even if the heuristic function is admissible, the $A^*$ graph search don't guarentee to give the optimal solution. For instance, if a series of node are 'over optimistic' so that they lead the agent to follow the wrong path and let it unable to return to the optimal path, since the node on it has already been expanded. To solve this problem, we need the heuristic function to be consistent. In other word, no heuristic function value will be 'over optimistic'. More formally, the consitent heuristic function has to obey the triangle inequality. Surprisingly, the heuristic function derived from the optimal solution of the relaxed problem obey the triangle inequality naturally, therefore, not only is it admissible, but it is also consistent. Whenever the heuristic function is consistent, the first time each node enter the frontier, it must be approached along the optimal path with minimum $g$ value.

### Simulating Annealing Algorithm

In Simulating Annealing Algorithm, there is a parameter called Temperature. Same as other searching algorithm, if there are better adjacent state, then the agent turn into that state. However, when there are no better adjacent state, there is possibility for the agent to leave the current state. The possibility is proportional to $e^{\frac{\Delta E}{T}}$, where $\Delta E$ is the difference between the 'score' of the two states.

### Adversial Searching

The original minimax algorithm for adversial searhing is similar to the *exhausted* DFS. In other word, it has to traverse all the possible state to return the final answer. It is actually a postorder search. Therefore, the time complexity is $O(b^m)$, and the space complexity is $O(bm)$

#### 形式化

确定性博弈的形式化描述：

- 状态
- 玩家
- 动作
- 转移模型
- 中止测试
- 效用函数

对于一个玩家而言，解是一个法则，能够为每个可能的状态指定一个动作。

#### $\alpha-\beta$Pruning

The essence of pruning is to use the information already got to decide whether continuing exploring some subtrees can make any change to the answer we want.

When thinking of $\alpha-\beta$ pruning, we must realized that the $\alpha$ or $\beta$ value we have already got represent some existing path, therefore, when we can show that the path passing by the current path will not be better than that existing path, we can pruning this node and the following subtree.

#### Expectiminimax

When randomness appear in the game, we have to take it into consideration. One way to do it is to use the expectiminimax instead of ordinary minimax. In other word, we have to consider each possible conditions and weigh they with their possiblity.

#### Multi-agent Game

Dynamic cooperations may arise in such cases, even if we don't intentionally let the agents do so. For example, when there are several ghosts in the pac-man game, since they goals are both eating the pac-man, and they act according to other's action to maximaize their scores, chances are that they may surround the pac-man so that the pac-man is doomed.

## Logic

- 逻辑：处理事实的形式化系统，目的是得到正确结论
- 语法：构造知识库有效句子的规则
- 语义：句子的“含义”，逻辑语句和真实世界之间的关系
- 蕴含：基于语义的句子之间的关系

- 判断逻辑蕴含的方法：
  - 模型检验
  - 逻辑规则
  - 定理证明

### Propositional Logic

The synatx are what sentences are allowed, while the semantics is what we follows to tell whether a given sentence is true or not in a given world, in other word, it is the truth itself.

Entailment is the conception of the logic itself and is defined only by the concept of synatx, semantics and world. More exactly
\[\alpha\models\beta iff M(\alpha)\subseteq M(\beta)\]

While implies$\Rightarrow$ is specific to certain kind of logic, such as porpositional logic.

